{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS\n",
    "# generate_data is modified version of https://github.com/cvxgrp/cvxbook_additional_exercises/blob/main/python/rob_logistic_reg_data.py\n",
    "np.random.seed(0x364a_23F5)\n",
    "d = 40\n",
    "n = 60\n",
    "def generate_data(eps):\n",
    "    \n",
    "    epsilon = eps\n",
    "\n",
    "    true_theta = np.random.randn(d)\n",
    "    true_X = np.random.randn(n, d)\n",
    "    noise = 2 * epsilon * np.random.rand(n, d) - epsilon\n",
    "\n",
    "    X = true_X + noise\n",
    "    y = np.sign(true_X @ true_theta + 0.1 * np.random.rand(n) - 0.05)\n",
    "\n",
    "    true_X_test = np.random.randn(n, d)\n",
    "    noise = 2 * epsilon * np.random.rand(n, d) - epsilon\n",
    "\n",
    "    X_test = true_X_test + noise\n",
    "    y_test = np.sign(true_X_test @ true_theta + 0.1 * np.random.rand(n) - 0.05)\n",
    "    return (X, y, X_test, y_test)\n",
    "\n",
    "def test_classifier(data_matrix, classifications, params):\n",
    "    num_correct = 0\n",
    "    for i in range(data_matrix.shape[0]):\n",
    "        y_hat = cp.sign(params @ data_matrix[i, :]).value\n",
    "        if y_hat == classifications[i]:\n",
    "            num_correct += 1\n",
    "    return num_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.68719193727882e-09"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a typical logistic classifier with eps = 1/2\n",
    "X, y, X_test, y_test = generate_data(0.5)\n",
    "\n",
    "theta = cp.Variable(d)\n",
    "lse = cp.logistic\n",
    "\n",
    "loss = cp.sum( [ lse( -y[i] * theta@X[i, :] ) for i in range(n)] )\n",
    "prob = cp.Problem(cp.Minimize(loss), [])\n",
    "prob.solve(solver=cp.CLARABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The non robust logist model correctly classified 60 data points with eps=0.5 of the training dataset\n",
      "The non robust logist model correctly classified 36 data points with eps=0.5 of the testing dataset\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "train_correct = test_classifier(X, y, theta)\n",
    "print(f\"The non robust logist model correctly classified {train_correct} data points with eps=0.5 of the training dataset\")\n",
    "train_correct = test_classifier(X_test, y_test, theta)\n",
    "print(f\"The non robust logist model correctly classified {train_correct} data points with eps=0.5 of the testing dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.48895006171033"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a robust classifier\n",
    "epsilon=0.5\n",
    "theta_robust = cp.Variable(d)\n",
    "u = cp.Variable(n)\n",
    "\n",
    "lse = cp.logistic\n",
    "\n",
    "loss = cp.sum( [ lse( u[i] ) for i in range(n)] )\n",
    "\n",
    "constrs = [ -y[i]*theta_robust@X[i, :] + cp.norm((-epsilon*y[i]*theta_robust), 1) <= u[i]\n",
    "           for i in range(n)]\n",
    "# Note the following doesn't work because y_i can equal -1, and then the constraint is not DCP compliant\n",
    "# constrs = [ -y[i]*theta_robust@X[i, :] + (-epsilon*y[i])*cp.norm(theta_robust, 1) <= u[i]\n",
    "#            for i in range(n)]\n",
    "\n",
    "prob = cp.Problem(cp.Minimize(loss), constrs)\n",
    "prob.solve(solver=cp.CLARABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The robust logist model correctly classified 47 data points with ell_inf uncertainty set, eps=0.5 of the training dataset\n",
      "The non robust logist model correctly classified 38 data points with ell_inf uncertainty set, eps=0.5 of the testing dataset\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "train_correct = test_classifier(X, y, theta_robust)\n",
    "print(f\"The robust logist model correctly classified {train_correct} data points with ell_inf uncertainty set, eps={epsilon} of the training dataset\")\n",
    "train_correct = test_classifier(X_test, y_test, theta_robust)\n",
    "print(f\"The non robust logist model correctly classified {train_correct} data points with ell_inf uncertainty set, eps={epsilon} of the testing dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.94963969089907"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a robust classifier with euclidean norm uncertainty\n",
    "epsilon=0.5\n",
    "theta_robust = cp.Variable(d)\n",
    "u = cp.Variable(n)\n",
    "\n",
    "lse = cp.logistic\n",
    "\n",
    "loss = cp.sum( [ lse( u[i] ) for i in range(n)] )\n",
    "\n",
    "constrs = [ -y[i]*theta_robust@X[i, :] + cp.norm((-epsilon*y[i]*theta_robust), 2) <= u[i]\n",
    "           for i in range(n)]\n",
    "# Note the following doesn't work because y_i can equal -1, and then the constraint is not DCP compliant\n",
    "# constrs = [ -y[i]*theta_robust@X[i, :] + (-epsilon*y[i])*cp.norm(theta_robust, 1) <= u[i]\n",
    "#            for i in range(n)]\n",
    "\n",
    "prob = cp.Problem(cp.Minimize(loss), constrs)\n",
    "prob.solve(solver=cp.CLARABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The robust logist model correctly classified 60 data points with ell_2 uncertainty set, eps=0.5 of the training dataset\n",
      "The non robust logist model correctly classified 49 data points with ell_2 uncertainty set, eps=0.5 of the testing dataset\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "train_correct = test_classifier(X, y, theta_robust)\n",
    "print(f\"The robust logist model correctly classified {train_correct} data points with ell_2 uncertainty set, eps={epsilon} of the training dataset\")\n",
    "train_correct = test_classifier(X_test, y_test, theta_robust)\n",
    "print(f\"The non robust logist model correctly classified {train_correct} data points with ell_2 uncertainty set, eps={epsilon} of the testing dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.003174191952969e-09"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a robust classifier with euclidean norm uncertainty\n",
    "epsilon=0.5\n",
    "theta_robust = cp.Variable(d)\n",
    "u = cp.Variable(n)\n",
    "\n",
    "lse = cp.logistic\n",
    "\n",
    "loss = cp.sum( [ lse( u[i] ) for i in range(n)] )\n",
    "\n",
    "constrs = [ -y[i]*theta_robust@X[i, :] + cp.norm((-epsilon*y[i]*theta_robust), 'inf') <= u[i]\n",
    "           for i in range(n)]\n",
    "# Note the following doesn't work because y_i can equal -1, and then the constraint is not DCP compliant\n",
    "# constrs = [ -y[i]*theta_robust@X[i, :] + (-epsilon*y[i])*cp.norm(theta_robust, 1) <= u[i]\n",
    "#            for i in range(n)]\n",
    "\n",
    "prob = cp.Problem(cp.Minimize(loss), constrs)\n",
    "prob.solve(solver=cp.CLARABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The robust logist model correctly classified 60 data points with ell_1 uncertainty set, eps=0.5 of the training dataset\n",
      "The non robust logist model correctly classified 47 data points with ell_1 uncertainty set, eps=0.5 of the testing dataset\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "train_correct = test_classifier(X, y, theta_robust)\n",
    "print(f\"The robust logist model correctly classified {train_correct} data points with ell_1 uncertainty set, eps={epsilon} of the training dataset\")\n",
    "train_correct = test_classifier(X_test, y_test, theta_robust)\n",
    "print(f\"The non robust logist model correctly classified {train_correct} data points with ell_1 uncertainty set, eps={epsilon} of the testing dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boyd_linear-algebra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
